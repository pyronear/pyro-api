name: scripts

on:
  push:
    branches: main
  pull_request:
    branches: main

jobs:
  end-to-end:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        python: [3.9]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}
          architecture: x64
      - uses: abatilo/actions-poetry@v3
        with:
          poetry-version: "1.8.2"
      - name: Resolve dependencies
        run: poetry export -f requirements.txt --without-hashes --output requirements.txt
      - name: Run the backend & the test
        env:
          BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
          BUCKET_MEDIA_FOLDER: ${{ secrets.BUCKET_MEDIA_FOLDER }}
          S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
          S3_ACCESS_KEY: ${{ secrets.S3_ACCESS_KEY }}
          S3_SECRET_KEY: ${{ secrets.S3_SECRET_KEY }}
          S3_REGION: ${{ secrets.S3_REGION }}
          SUPERUSER_LOGIN: dummy_login
          SUPERUSER_PWD: dummy&P@ssw0rd!
          POSTGRES_USER: dummy_pg_user
          POSTGRES_PASSWORD: dummy_pg_pwd
          POSTGRES_DB: dummy_pg_db
        run: |
          docker volume prune -f
          docker compose up -d --build
          docker ps
      - name: Run end-to-end integration test
        env:
          SUPERUSER_LOGIN: dummy_login
          SUPERUSER_PWD: dummy&P@ssw0rd!
        run: |
          python -m pip install --upgrade uv
          uv pip install --system -r scripts/requirements.txt
          sleep 5
          python scripts/api_e2e.py 8080
